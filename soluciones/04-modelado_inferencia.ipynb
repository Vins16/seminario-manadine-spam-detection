{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelado\n",
    "\n",
    "En este notebook utilizaremos los conjuntos que hemos inspeccionado y adecuado para realizar modelos que nos ayude a analizar los mensajes de texto y detectar si se trata de **spam** o menos.\n",
    "\n",
    "El siguiente script está dividido en los siguientes bloques:\n",
    "\n",
    "- **BLOQUE A**: carga de datos preprocesados.\n",
    "\n",
    "- **BLOQUE B**: entrenamiento y inferencia con distintos modelos de ML.\n",
    "\n",
    "- **BLOQUE C**: entrenamiento y inferencia con una red neuronal.\n",
    "\n",
    "- **BLOQUE D**: transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 10:25:59.418709: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-26 10:26:00.958127: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-26 10:26:00.965374: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-26 10:26:02.847907: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import TFDistilBertForSequenceClassification, DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOQUE A: Carga de datos\n",
    "Antes de comenzar, cargaremos los datos que han sido adecuados en nuestra fase anterior de preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga textos vectorizados\n",
    "with open('../data/x_train_vec.pkl', 'rb') as f:\n",
    "    X_train_vec = pickle.load(f)\n",
    "\n",
    "with open('../data/x_test_vec.pkl', 'rb') as f:\n",
    "    X_test_vec = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga conjuntos de las etiquetas\n",
    "with open('../data/y_train.pkl', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open('../data/y_test.pkl', 'rb') as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOQUE B: Entrenamiento de distinto modelos de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión logistica\n",
    "\n",
    "La regresión logística es un método de clasificación que modela la probabilidad de eventos binarios. Utilizando la función sigmoide, asigna valores entre 0 y 1, facilitando la predicción de categorías, como positivo o negativos, spam o no spam, en aplicaciones prácticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo\n",
    "log_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento o ajuste del modelo con los datos de entrenamiento\n",
    "log_model.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados conjunto de entrenamiento:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.99      0.98       589\n",
      "        spam       0.99      0.96      0.97       590\n",
      "\n",
      "    accuracy                           0.97      1179\n",
      "   macro avg       0.98      0.97      0.97      1179\n",
      "weighted avg       0.98      0.97      0.97      1179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos sobre los datos de entrenamiento\n",
    "y_pred_train = log_model.predict(X_train_vec)\n",
    "\n",
    "# Mostramos el \"classification report\"\n",
    "print('Resultados conjunto de entrenamiento:\\n')\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados conjunto de test:\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      0.96      0.94       148\n",
      "        spam       0.96      0.93      0.94       147\n",
      "\n",
      "    accuracy                           0.94       295\n",
      "   macro avg       0.94      0.94      0.94       295\n",
      "weighted avg       0.94      0.94      0.94       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos sobre los datos de test\n",
    "y_pred_test = log_model.predict(X_test_vec)\n",
    "\n",
    "# Mostramos el \"classification report\" y \"accuracy\"\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print('Resultados conjunto de test:\\n')\n",
    "print(f'Accuracy: {accuracy:.2f}\\n')\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué es Boosting?\n",
    "\n",
    "Boosting es un meta-algoritmo de aprendizaje automático que reduce el sesgo y la varianza en un contexto de aprendizaje supervisado. Consiste en combinar los resultados de varios clasificadores débiles para obtener un clasificador robusto. Cuando se añaden estos clasificadores débiles, se hace de modo que éstos tengan diferente peso en función de la exactitud de sus predicciones. Tras añadir un clasificador débil, los datos cambian su estructura de pesos: los casos mal clasificados ganan peso y los que son clasificados correctamente pierden peso.\n",
    "\n",
    "**Gradient Boosting (GB)** o Potenciación del gradiente consiste en plantear el problema como una optimización numérica en el que el objetivo es minimizar una función de coste añadiendo clasificadores débiles mediante el descenso del gradiente. Involucra tres elementos:\n",
    "\n",
    "- La **función de coste** a optimizar: depende del tipo de problema a resolver.\n",
    "- Un **clasificador débil** para hacer las predicciones: por lo general se usan árboles de decisión.\n",
    "- Un **modelo que añade (ensambla) los clasificadores débiles para minimizar la función de coste**: se usa el descenso del gradiente para minimizar el coste al añadir árboles.\n",
    "\n",
    "Los hiperparámetros más importantes que intervienen en este algoritmo (aunque no todos) son:\n",
    "\n",
    "- **learning_rate**: determina el impacto de cada árbol en la salida final. Se parte de una estimación inicial que se va actualizando con la salida de cada árbol. Es el parámetro que controla la magnitud de las actualizaciones.\n",
    "- **n_estimators**: número de clasificadores débiles a utilizar.\n",
    "\n",
    "Como en este caso utilizaremos árboles de decisión como clasificadores débiles a ensamblar, también debemos tener en cuenta los hiperparámetros que afectan a esta clase de modelos. En este caso:\n",
    "\n",
    "- **max_depth**: profundidad máxima del árbol.\n",
    "\n",
    "Más información sobre el modelo que se utiliza en este ejemplo y de sus parámetros [aquí](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo introduciendo los valores de los parámetros:\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=150, learning_rate=0.2, max_depth=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=0.2, n_estimators=150, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.2, n_estimators=150, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.2, n_estimators=150, random_state=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento o ajuste del modelo con los datos de entrenamiento\n",
    "gb_clf.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados conjunto de entrenamiento:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00       589\n",
      "        spam       1.00      1.00      1.00       590\n",
      "\n",
      "    accuracy                           1.00      1179\n",
      "   macro avg       1.00      1.00      1.00      1179\n",
      "weighted avg       1.00      1.00      1.00      1179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos sobre los datos de entrenamiento\n",
    "pred_train = gb_clf.predict(X_train_vec)\n",
    "\n",
    "# Mostramos el \"classification report\"\n",
    "print('Resultados conjunto de entrenamiento:\\n')\n",
    "print(classification_report(y_train, pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados conjunto de test:\n",
      "\n",
      "Accuracy: 0.89\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.93      0.90       148\n",
      "        spam       0.93      0.86      0.89       147\n",
      "\n",
      "    accuracy                           0.89       295\n",
      "   macro avg       0.90      0.89      0.89       295\n",
      "weighted avg       0.90      0.89      0.89       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos sobre los datos de test\n",
    "pred_test = gb_clf.predict(X_test_vec)\n",
    "\n",
    "# Mostramos el \"classification report\" y \"accuracy\"\n",
    "accuracy = accuracy_score(y_test, pred_test)\n",
    "print('Resultados conjunto de test:\\n')\n",
    "print(f'Accuracy: {accuracy:.2f}\\n')\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOQUE C: entrenamiento y inferencia con una red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text  length\n",
       "0    ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "2    ham  U dun say so early hor... U c already then say...      49\n",
       "3    ham  Nah I don't think he goes to usf, he lives aro...      61\n",
       "4   spam  FreeMsg Hey there darling it's been 3 week's n...     148"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el dataset (ajusta la ruta según el archivo que tengas)\n",
    "df = pd.read_csv('../data/spam_filtered.csv')\n",
    "\n",
    "# Verifica el dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento del texto\n",
    "X = df['text']  # Supón que la columna 'text' contiene los mensajes\n",
    "y = df['target']  # 'label' debe ser spam/no spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las etiquetas 'spam'/'ham' a números\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ¿Que valores asume la variale target transformada? \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam', 'ham', ..., 'ham', 'ham', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ¿A qué corresponden los nuevos valores?\n",
    "df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenización y padding para convertir el texto en secuencias de enteros\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 370,\n",
       " 813,\n",
       " 5,\n",
       " 746,\n",
       " 69,\n",
       " 2401,\n",
       " 321,\n",
       " 88,\n",
       " 549,\n",
       " 300,\n",
       " 69,\n",
       " 2402,\n",
       " 2403,\n",
       " 2404,\n",
       " 321,\n",
       " 99,\n",
       " 814,\n",
       " 2405,\n",
       " 1893,\n",
       " 196,\n",
       " 116,\n",
       " 370,\n",
       " 815,\n",
       " 18,\n",
       " 2406,\n",
       " 116,\n",
       " 746,\n",
       " 2407,\n",
       " 65,\n",
       " 5,\n",
       " 2408,\n",
       " 57,\n",
       " 2409,\n",
       " 1179,\n",
       " 116,\n",
       " 746,\n",
       " 1894,\n",
       " 16,\n",
       " 57,\n",
       " 76,\n",
       " 18,\n",
       " 691,\n",
       " 116,\n",
       " 371,\n",
       " 116,\n",
       " 370,\n",
       " 1540,\n",
       " 56,\n",
       " 1180,\n",
       " 80,\n",
       " 1541,\n",
       " 99,\n",
       " 88,\n",
       " 494,\n",
       " 2410,\n",
       " 1895,\n",
       " 7,\n",
       " 495,\n",
       " 26,\n",
       " 692,\n",
       " 883,\n",
       " 116,\n",
       " 370,\n",
       " 1333,\n",
       " 1334,\n",
       " 9,\n",
       " 116,\n",
       " 693,\n",
       " 14,\n",
       " 11,\n",
       " 816,\n",
       " 80,\n",
       " 1896,\n",
       " 116,\n",
       " 371,\n",
       " 1897,\n",
       " 85,\n",
       " 816,\n",
       " 80,\n",
       " 2411,\n",
       " 2412,\n",
       " 2413,\n",
       " 2414,\n",
       " 1898,\n",
       " 1334,\n",
       " 2415,\n",
       " 1181,\n",
       " 14,\n",
       " 116,\n",
       " 694,\n",
       " 3,\n",
       " 1335,\n",
       " 47,\n",
       " 695,\n",
       " 116,\n",
       " 306,\n",
       " 817]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ¿Come se transorma los textos con Tokenizer?\n",
    "X_train_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding para asegurar que todas las secuencias tengan la misma longitud\n",
    "X_train_pad = pad_sequences(X_train_seq, padding='post', maxlen=100)\n",
    "X_test_pad = pad_sequences(X_test_seq, padding='post', maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estructura de la red neuronal:\n",
    "1. Capa de Embedding: \n",
    "    - input_dim=10000: Esto se refiere al tamaño del vocabulario (número total de palabras). \n",
    "\n",
    "    - output_dim=64: Este especifica la dimensión de los embeddings. En lugar de representar cada palabra con un valor binario o en un vector disperso (como ocurre con BoW o TF-IDF), las palabras se representarán por un vector denso de 64 dimensiones. \n",
    "\n",
    "    - input_length=100: se define la longitud máxima de las secuencias de entrada. Cada entrada de texto se convierte en una secuencia de índices de palabras (tokens), y si la longitud de una secuencia es menor que 100, se rellenará con ceros. Si es mayor, se truncará.\n",
    "2. Capa de Pooling: Esta capa realiza un *pooling global promedio* sobre las secuencias de embeddings. Dado que las entradas son secuencias de longitud 100, esta capa tomará el promedio de los vectores de embeddings de las 100 palabras (tokens) en la secuencia, lo que reduce la representación de la secuencia de una matriz de 100x64 a un solo vector de 64 dimensiones\n",
    "\n",
    "3. Capa densa (Fully connected): Esta capa toma la salida del pooling (un vector de 64 dimensiones) y lo pasa a través de una **capa densa con 64 neuronas** y la **función de activación ReLU**. Esto ayuda a la red a aprender características más complejas del texto procesado.\n",
    "\n",
    "4. Capa de salida: esta capa tiene una sola neurona con la **función de activación Sigmoid**, que es adecuada para clasificación binaria (en este caso, para clasificar como spam o no spam). La salida de esta capa será un valor entre 0 y 1, que puedes interpretar como la probabilidad de que un mensaje sea spam.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo simple de red neuronal para clasificación de texto\n",
    "nn_simple = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=10000, output_dim=64, input_length=100),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Para clasificación binaria (spam/no spam)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "nn_simple.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "nn_simple.fit(X_train_pad, y_train, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predecimos sobre los datos de test\n",
    "pred_test = nn_simple.predict(X_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.63494784e-04],\n",
       "       [9.99683559e-01],\n",
       "       [9.99902785e-01],\n",
       "       [1.25901715e-04],\n",
       "       [1.63715403e-03],\n",
       "       [3.20897717e-03],\n",
       "       [1.99610298e-03],\n",
       "       [4.88012331e-03],\n",
       "       [9.99916255e-01],\n",
       "       [1.52244326e-03],\n",
       "       [5.41562820e-03],\n",
       "       [7.90504813e-01],\n",
       "       [9.99728560e-01],\n",
       "       [1.01553982e-04],\n",
       "       [8.08721161e-05],\n",
       "       [1.35890897e-02],\n",
       "       [5.92035009e-04],\n",
       "       [6.29816859e-05],\n",
       "       [9.98020172e-01],\n",
       "       [4.49418367e-05],\n",
       "       [3.18931462e-03],\n",
       "       [7.11744884e-03],\n",
       "       [6.83361478e-03],\n",
       "       [9.99737680e-01],\n",
       "       [2.80932756e-03],\n",
       "       [4.34677536e-03],\n",
       "       [5.57146817e-02],\n",
       "       [9.99936640e-01],\n",
       "       [1.73422508e-02],\n",
       "       [5.21538139e-04],\n",
       "       [3.72867973e-04],\n",
       "       [7.31132575e-04],\n",
       "       [9.66990113e-01],\n",
       "       [9.72566247e-01],\n",
       "       [9.98693287e-01],\n",
       "       [9.99632239e-01],\n",
       "       [3.23799141e-02],\n",
       "       [2.94691529e-02],\n",
       "       [4.27135004e-04],\n",
       "       [1.85513988e-01],\n",
       "       [1.49937638e-03],\n",
       "       [9.99332607e-01],\n",
       "       [1.72342092e-03],\n",
       "       [9.99921501e-01],\n",
       "       [1.86706763e-02],\n",
       "       [9.99122024e-01],\n",
       "       [3.65843833e-03],\n",
       "       [6.38474885e-04],\n",
       "       [1.95685960e-03],\n",
       "       [1.29682489e-03],\n",
       "       [5.29297534e-03],\n",
       "       [2.47729886e-02],\n",
       "       [2.17521843e-02],\n",
       "       [6.86910748e-03],\n",
       "       [4.13359888e-02],\n",
       "       [9.99657750e-01],\n",
       "       [1.98064768e-03],\n",
       "       [9.99914050e-01],\n",
       "       [9.35646123e-04],\n",
       "       [4.65820869e-03],\n",
       "       [6.54211966e-04],\n",
       "       [8.58243406e-02],\n",
       "       [5.91097050e-04],\n",
       "       [8.00669007e-03],\n",
       "       [9.99454975e-01],\n",
       "       [9.50508356e-01],\n",
       "       [1.89042196e-03],\n",
       "       [1.09510205e-03],\n",
       "       [8.11282825e-03],\n",
       "       [1.62837314e-04],\n",
       "       [3.99581681e-04],\n",
       "       [4.69048955e-02],\n",
       "       [1.58825256e-02],\n",
       "       [9.99789596e-01],\n",
       "       [5.10597927e-03],\n",
       "       [4.68787923e-03],\n",
       "       [1.21445613e-04],\n",
       "       [1.99992122e-04],\n",
       "       [1.47754364e-02],\n",
       "       [1.26697822e-03],\n",
       "       [9.99921739e-01],\n",
       "       [9.99797583e-01],\n",
       "       [3.97603115e-04],\n",
       "       [5.85947237e-05],\n",
       "       [2.94934056e-04],\n",
       "       [4.72965592e-04],\n",
       "       [6.92195899e-05],\n",
       "       [2.36962427e-04],\n",
       "       [9.97429550e-01],\n",
       "       [9.96353209e-01],\n",
       "       [1.89042196e-03],\n",
       "       [2.50937394e-03],\n",
       "       [9.93361652e-01],\n",
       "       [7.81277995e-05],\n",
       "       [4.93558109e-05],\n",
       "       [1.93464430e-03],\n",
       "       [2.57258216e-04],\n",
       "       [1.44340489e-02],\n",
       "       [8.82556997e-05],\n",
       "       [6.14319462e-04],\n",
       "       [4.43746248e-04],\n",
       "       [2.62345129e-04],\n",
       "       [3.34071815e-01],\n",
       "       [3.54854134e-03],\n",
       "       [3.58704180e-02],\n",
       "       [1.83759804e-03],\n",
       "       [3.56681674e-04],\n",
       "       [4.40473203e-03],\n",
       "       [3.94549314e-03],\n",
       "       [9.99602556e-01],\n",
       "       [7.04861595e-04],\n",
       "       [9.99709547e-01],\n",
       "       [3.57982959e-03],\n",
       "       [8.43029097e-03],\n",
       "       [9.99692142e-01],\n",
       "       [2.90566415e-04],\n",
       "       [2.69789877e-03],\n",
       "       [9.99744475e-01],\n",
       "       [7.87468889e-05],\n",
       "       [5.49740950e-03],\n",
       "       [1.15141822e-02],\n",
       "       [1.49367945e-04],\n",
       "       [2.36891732e-02],\n",
       "       [3.42730852e-03],\n",
       "       [4.74434048e-02],\n",
       "       [4.28554369e-03],\n",
       "       [9.99701440e-01],\n",
       "       [9.98222172e-01],\n",
       "       [1.32285655e-02],\n",
       "       [1.30352113e-04],\n",
       "       [2.43653223e-04],\n",
       "       [1.13921997e-05],\n",
       "       [1.33519410e-04],\n",
       "       [7.10821132e-06],\n",
       "       [5.18983006e-01],\n",
       "       [1.29769102e-03],\n",
       "       [9.99728799e-01],\n",
       "       [2.10580970e-06],\n",
       "       [6.57521002e-03],\n",
       "       [4.80374927e-03],\n",
       "       [1.31070167e-01],\n",
       "       [1.46926392e-03],\n",
       "       [3.52893048e-03],\n",
       "       [5.45183830e-02],\n",
       "       [8.43293034e-03],\n",
       "       [9.99620855e-01],\n",
       "       [4.64797515e-04],\n",
       "       [2.26210002e-02],\n",
       "       [4.52016306e-04],\n",
       "       [1.51766615e-03],\n",
       "       [8.19794089e-03],\n",
       "       [8.90877564e-04],\n",
       "       [1.17239084e-04],\n",
       "       [5.09234099e-03],\n",
       "       [5.41763427e-03],\n",
       "       [1.19497639e-03],\n",
       "       [3.79939228e-02],\n",
       "       [1.06107342e-04],\n",
       "       [1.16775222e-01],\n",
       "       [9.75570440e-01],\n",
       "       [6.46112952e-03],\n",
       "       [1.29094459e-02],\n",
       "       [1.97430979e-03],\n",
       "       [3.57349083e-04],\n",
       "       [9.99784827e-01],\n",
       "       [7.61758722e-03],\n",
       "       [1.72059095e-04],\n",
       "       [3.68205830e-03],\n",
       "       [6.65937969e-03],\n",
       "       [2.03388845e-05],\n",
       "       [3.87746986e-04],\n",
       "       [7.91927397e-01],\n",
       "       [9.73337796e-03],\n",
       "       [3.12798396e-02],\n",
       "       [8.14941619e-03],\n",
       "       [1.21458819e-04],\n",
       "       [2.05967221e-02],\n",
       "       [2.86491650e-05],\n",
       "       [5.33859245e-03],\n",
       "       [1.16912660e-03],\n",
       "       [1.02114580e-04],\n",
       "       [4.21035133e-04],\n",
       "       [5.86735737e-03],\n",
       "       [3.26029578e-04],\n",
       "       [1.23483216e-04],\n",
       "       [3.01025063e-02],\n",
       "       [9.84126747e-01],\n",
       "       [5.27979224e-04],\n",
       "       [3.04856483e-04],\n",
       "       [4.50931606e-04],\n",
       "       [1.02870748e-04],\n",
       "       [3.84991523e-04],\n",
       "       [1.29260086e-02],\n",
       "       [1.81063326e-04],\n",
       "       [1.73083262e-03],\n",
       "       [3.58552788e-05],\n",
       "       [3.87646943e-01],\n",
       "       [1.08625996e-03],\n",
       "       [9.97958601e-01],\n",
       "       [1.35844445e-03],\n",
       "       [9.08592192e-05],\n",
       "       [1.42210966e-03],\n",
       "       [3.72149318e-01],\n",
       "       [9.89076914e-04],\n",
       "       [1.64916448e-04],\n",
       "       [9.97892201e-01],\n",
       "       [9.34597920e-04],\n",
       "       [4.24467231e-04],\n",
       "       [5.32133214e-04],\n",
       "       [6.48342364e-04],\n",
       "       [9.99819398e-01],\n",
       "       [4.12154291e-03],\n",
       "       [5.67720085e-03],\n",
       "       [2.46204846e-02],\n",
       "       [8.69323127e-03],\n",
       "       [1.84335222e-03],\n",
       "       [2.91314209e-03],\n",
       "       [8.15548468e-03],\n",
       "       [9.99954164e-01],\n",
       "       [6.86274767e-01],\n",
       "       [1.32953646e-02],\n",
       "       [1.33439258e-03],\n",
       "       [3.02381106e-02],\n",
       "       [1.21484464e-02],\n",
       "       [1.16472626e-02],\n",
       "       [8.73171724e-04],\n",
       "       [5.08072495e-04],\n",
       "       [4.64088097e-03],\n",
       "       [1.05666593e-02],\n",
       "       [9.54784453e-03],\n",
       "       [9.99809742e-01],\n",
       "       [2.71003773e-05],\n",
       "       [1.49937638e-03],\n",
       "       [6.12498960e-03],\n",
       "       [1.13266278e-05],\n",
       "       [8.06277990e-02],\n",
       "       [6.00811653e-03],\n",
       "       [2.02562966e-04],\n",
       "       [1.87215657e-04],\n",
       "       [6.29157468e-04],\n",
       "       [3.72833759e-03],\n",
       "       [2.28448291e-04],\n",
       "       [4.26793471e-03],\n",
       "       [1.21682599e-01],\n",
       "       [1.55300531e-03],\n",
       "       [1.84478913e-03],\n",
       "       [3.62435356e-03],\n",
       "       [1.08120581e-02],\n",
       "       [1.69181862e-04],\n",
       "       [1.52732086e-04],\n",
       "       [9.96865988e-01],\n",
       "       [1.17761432e-03],\n",
       "       [1.79054783e-04],\n",
       "       [6.09078050e-01],\n",
       "       [1.95178480e-04],\n",
       "       [8.55977461e-03],\n",
       "       [5.95990475e-03],\n",
       "       [1.46697955e-02],\n",
       "       [9.95558202e-01],\n",
       "       [3.59502179e-03],\n",
       "       [7.70272745e-04],\n",
       "       [9.99311268e-01],\n",
       "       [1.06394454e-03],\n",
       "       [1.29352836e-02],\n",
       "       [9.87033709e-04],\n",
       "       [1.44657533e-04],\n",
       "       [6.71578673e-05],\n",
       "       [1.38094521e-03],\n",
       "       [1.00130055e-05],\n",
       "       [2.34547420e-03],\n",
       "       [6.34809434e-01],\n",
       "       [1.83701719e-04],\n",
       "       [9.99947548e-01],\n",
       "       [9.99444723e-01],\n",
       "       [1.39518986e-02],\n",
       "       [2.42739413e-02],\n",
       "       [1.01232217e-04],\n",
       "       [1.17508573e-02],\n",
       "       [2.04316843e-02],\n",
       "       [2.14013809e-04],\n",
       "       [4.60482879e-05],\n",
       "       [4.33996283e-05],\n",
       "       [5.40984189e-03],\n",
       "       [2.18922927e-04],\n",
       "       [9.99972165e-01],\n",
       "       [9.10357805e-04],\n",
       "       [1.57200906e-04],\n",
       "       [5.13204082e-04],\n",
       "       [3.25549692e-02],\n",
       "       [2.22253118e-04],\n",
       "       [9.98817325e-01],\n",
       "       [3.55724851e-03],\n",
       "       [4.53340384e-04],\n",
       "       [3.76852540e-06],\n",
       "       [9.73515213e-01],\n",
       "       [2.71211757e-04],\n",
       "       [9.36178677e-03],\n",
       "       [1.63429475e-04],\n",
       "       [9.96392012e-01],\n",
       "       [5.98610612e-04],\n",
       "       [2.81784516e-02],\n",
       "       [1.72702549e-03],\n",
       "       [8.41016663e-06],\n",
       "       [9.53454673e-01],\n",
       "       [5.23045543e-04],\n",
       "       [1.38062483e-03],\n",
       "       [3.07582729e-02],\n",
       "       [2.79873493e-04],\n",
       "       [9.99069393e-01],\n",
       "       [9.68492532e-04],\n",
       "       [2.30908026e-05],\n",
       "       [1.36697679e-04],\n",
       "       [9.99315619e-01],\n",
       "       [6.34531989e-06],\n",
       "       [2.92903860e-03],\n",
       "       [9.99256611e-01],\n",
       "       [9.25990811e-04],\n",
       "       [2.01879092e-03],\n",
       "       [9.95768368e-01],\n",
       "       [9.99574363e-01],\n",
       "       [9.99673307e-01],\n",
       "       [3.53765897e-02],\n",
       "       [2.27718870e-03],\n",
       "       [1.43036159e-04],\n",
       "       [2.01241011e-04],\n",
       "       [4.77118283e-06],\n",
       "       [1.37306470e-02],\n",
       "       [9.88641322e-01],\n",
       "       [4.67285099e-05],\n",
       "       [2.12355793e-04],\n",
       "       [5.74816018e-04],\n",
       "       [9.96014535e-01],\n",
       "       [4.95656487e-03],\n",
       "       [1.47155851e-01],\n",
       "       [9.99780655e-01],\n",
       "       [9.98793304e-01],\n",
       "       [9.12195355e-06],\n",
       "       [9.66384355e-03],\n",
       "       [2.18050482e-04],\n",
       "       [1.22142211e-03],\n",
       "       [1.26436263e-01],\n",
       "       [4.95989341e-03],\n",
       "       [9.99724746e-01],\n",
       "       [9.99452114e-01],\n",
       "       [1.96949659e-05],\n",
       "       [1.63655402e-03],\n",
       "       [1.17518138e-02],\n",
       "       [9.99522567e-01],\n",
       "       [2.80623237e-04],\n",
       "       [4.32198256e-04],\n",
       "       [4.24041027e-05],\n",
       "       [8.35462939e-03],\n",
       "       [9.55714495e-05],\n",
       "       [2.61779409e-04],\n",
       "       [8.15616455e-03],\n",
       "       [7.34277774e-06],\n",
       "       [2.19250160e-05],\n",
       "       [8.56586754e-01],\n",
       "       [3.82520165e-03],\n",
       "       [2.83458241e-04],\n",
       "       [3.93029157e-04],\n",
       "       [3.13543511e-04],\n",
       "       [3.18930135e-04],\n",
       "       [8.60255823e-05],\n",
       "       [3.21722589e-04],\n",
       "       [5.03283751e-04],\n",
       "       [4.14975220e-04],\n",
       "       [3.20942607e-03],\n",
       "       [4.09140810e-03],\n",
       "       [5.56870655e-04],\n",
       "       [1.15674846e-02],\n",
       "       [9.69759002e-03],\n",
       "       [8.16491339e-03],\n",
       "       [2.68141776e-02],\n",
       "       [1.40892877e-03],\n",
       "       [4.18751407e-03],\n",
       "       [3.69714893e-04],\n",
       "       [6.90249121e-03],\n",
       "       [9.98074055e-01],\n",
       "       [1.66625390e-03],\n",
       "       [1.88251659e-02],\n",
       "       [1.51976506e-04],\n",
       "       [4.30435920e-03],\n",
       "       [1.20214630e-04],\n",
       "       [2.59206688e-04],\n",
       "       [9.98598218e-01],\n",
       "       [9.98875439e-01],\n",
       "       [8.03058874e-03],\n",
       "       [2.06380500e-03],\n",
       "       [1.10983193e-01],\n",
       "       [6.77805627e-04],\n",
       "       [1.56532755e-04],\n",
       "       [9.99734461e-01],\n",
       "       [2.73967907e-03],\n",
       "       [1.38995675e-02],\n",
       "       [7.83384254e-04],\n",
       "       [9.50508356e-01],\n",
       "       [9.99941647e-01],\n",
       "       [9.99645531e-01],\n",
       "       [3.77101335e-03],\n",
       "       [5.87481633e-03],\n",
       "       [9.33187842e-01],\n",
       "       [2.10103142e-04],\n",
       "       [1.59513904e-03],\n",
       "       [9.99884903e-01],\n",
       "       [6.23468251e-04],\n",
       "       [4.37911731e-05],\n",
       "       [3.46916291e-04],\n",
       "       [4.53749672e-03],\n",
       "       [3.72540380e-05],\n",
       "       [9.99396145e-01],\n",
       "       [9.99924898e-01],\n",
       "       [9.05337918e-04],\n",
       "       [1.61712087e-04],\n",
       "       [9.39859569e-01],\n",
       "       [1.02969083e-04],\n",
       "       [1.27961824e-03],\n",
       "       [1.06369227e-03],\n",
       "       [2.33320650e-04],\n",
       "       [4.35854861e-04],\n",
       "       [2.35031155e-04],\n",
       "       [2.68802177e-02],\n",
       "       [9.98739541e-01],\n",
       "       [1.05363398e-03],\n",
       "       [7.45733874e-03],\n",
       "       [3.79660469e-03],\n",
       "       [1.88862992e-04],\n",
       "       [9.98625994e-01],\n",
       "       [5.38334243e-05],\n",
       "       [2.84134620e-03],\n",
       "       [5.05137490e-04],\n",
       "       [1.64616082e-04],\n",
       "       [7.71242543e-04],\n",
       "       [2.60728952e-02],\n",
       "       [1.79547053e-02],\n",
       "       [2.20173490e-04],\n",
       "       [3.17520316e-04],\n",
       "       [7.71135310e-05],\n",
       "       [1.77740045e-02],\n",
       "       [6.87937485e-03],\n",
       "       [4.21463599e-04],\n",
       "       [1.79453741e-03],\n",
       "       [3.93649675e-02],\n",
       "       [2.19913331e-04],\n",
       "       [1.10382342e-03],\n",
       "       [9.99641955e-01],\n",
       "       [1.73491146e-03],\n",
       "       [6.64090612e-06],\n",
       "       [1.89042196e-03],\n",
       "       [1.61446643e-03],\n",
       "       [7.85617813e-05],\n",
       "       [2.61676703e-02],\n",
       "       [2.27673445e-02],\n",
       "       [1.04797992e-03],\n",
       "       [9.94581450e-03],\n",
       "       [1.48748618e-03],\n",
       "       [1.28578944e-02],\n",
       "       [9.99452353e-01],\n",
       "       [9.99612391e-01],\n",
       "       [2.36337259e-03],\n",
       "       [1.23129960e-03],\n",
       "       [2.30749705e-04],\n",
       "       [5.40486677e-03],\n",
       "       [1.53428628e-04],\n",
       "       [2.72945890e-05],\n",
       "       [8.92972050e-04],\n",
       "       [9.79154865e-05],\n",
       "       [9.93948340e-01],\n",
       "       [2.69291967e-01],\n",
       "       [6.60967827e-02],\n",
       "       [9.99626219e-01],\n",
       "       [9.99707401e-01],\n",
       "       [2.76850220e-02],\n",
       "       [2.58247112e-03],\n",
       "       [4.24483083e-02],\n",
       "       [6.00196479e-04],\n",
       "       [1.73580623e-03],\n",
       "       [9.98979807e-01],\n",
       "       [5.43588120e-03],\n",
       "       [5.38900940e-06],\n",
       "       [3.64971551e-04],\n",
       "       [4.18293104e-03],\n",
       "       [1.27457629e-03],\n",
       "       [1.38104754e-02],\n",
       "       [8.77605565e-03],\n",
       "       [9.99315619e-01],\n",
       "       [3.66220158e-03],\n",
       "       [3.57114273e-04],\n",
       "       [9.99129355e-01],\n",
       "       [4.04498354e-03],\n",
       "       [2.12258240e-03],\n",
       "       [8.42410664e-04],\n",
       "       [9.22697582e-05],\n",
       "       [7.04692575e-05],\n",
       "       [9.99950469e-01],\n",
       "       [4.16156230e-03],\n",
       "       [1.74581504e-03],\n",
       "       [5.40281981e-02],\n",
       "       [9.05684792e-05],\n",
       "       [5.42413350e-03],\n",
       "       [2.10073878e-04],\n",
       "       [1.20748744e-04],\n",
       "       [9.45604086e-01],\n",
       "       [7.29118288e-02],\n",
       "       [2.19432474e-03],\n",
       "       [1.63715403e-03],\n",
       "       [4.27712366e-04],\n",
       "       [3.26009089e-04],\n",
       "       [8.40999055e-05],\n",
       "       [3.98018426e-04],\n",
       "       [1.30741129e-04],\n",
       "       [1.14470739e-02],\n",
       "       [2.65070033e-04],\n",
       "       [9.99915123e-01],\n",
       "       [5.96154062e-03],\n",
       "       [9.99790132e-01],\n",
       "       [1.30730146e-03],\n",
       "       [8.17189575e-04],\n",
       "       [4.24391776e-03],\n",
       "       [5.67109499e-04],\n",
       "       [3.52893048e-03],\n",
       "       [1.07410792e-02],\n",
       "       [9.41356182e-01],\n",
       "       [2.89685122e-04],\n",
       "       [5.11319563e-03],\n",
       "       [1.84044428e-02],\n",
       "       [1.77347774e-05],\n",
       "       [9.99941289e-01],\n",
       "       [1.00397162e-01],\n",
       "       [2.12757281e-04],\n",
       "       [8.17804262e-02],\n",
       "       [5.03443647e-03],\n",
       "       [1.12430775e-04],\n",
       "       [9.99854803e-01],\n",
       "       [1.95849072e-02],\n",
       "       [1.84270255e-02],\n",
       "       [2.43132445e-03],\n",
       "       [9.41570103e-01],\n",
       "       [9.76897180e-01],\n",
       "       [2.05967221e-02],\n",
       "       [9.99735296e-01],\n",
       "       [2.77989660e-03],\n",
       "       [7.76174129e-05],\n",
       "       [9.99319553e-01],\n",
       "       [2.74277874e-04],\n",
       "       [3.98127316e-03],\n",
       "       [8.70322227e-04],\n",
       "       [3.87690472e-03],\n",
       "       [9.98662412e-01],\n",
       "       [4.99123521e-02],\n",
       "       [3.16724851e-04],\n",
       "       [1.93866447e-03],\n",
       "       [5.31513069e-05],\n",
       "       [3.42703890e-04],\n",
       "       [6.84025930e-03],\n",
       "       [3.01900487e-02],\n",
       "       [7.04047561e-04],\n",
       "       [2.68621108e-04],\n",
       "       [2.29307450e-04],\n",
       "       [2.68763420e-03],\n",
       "       [9.19047058e-01],\n",
       "       [9.73000806e-06],\n",
       "       [4.32638917e-04],\n",
       "       [7.28948798e-04],\n",
       "       [2.94639380e-03],\n",
       "       [6.52016024e-05],\n",
       "       [3.02572269e-03],\n",
       "       [2.18050482e-04],\n",
       "       [2.32648687e-04],\n",
       "       [9.72278067e-05],\n",
       "       [1.98464189e-03],\n",
       "       [1.50035994e-04],\n",
       "       [8.55837425e-05],\n",
       "       [9.45604086e-01],\n",
       "       [3.96233611e-02],\n",
       "       [4.02565747e-01],\n",
       "       [6.63995525e-05],\n",
       "       [5.19815367e-03],\n",
       "       [1.11428471e-02],\n",
       "       [1.28966488e-03],\n",
       "       [1.07712862e-04],\n",
       "       [2.23504975e-02],\n",
       "       [8.40113426e-05],\n",
       "       [2.64479071e-02],\n",
       "       [8.70182994e-05],\n",
       "       [1.38623305e-04],\n",
       "       [4.96840151e-03],\n",
       "       [3.81443184e-04],\n",
       "       [3.13897937e-04],\n",
       "       [1.20789371e-03],\n",
       "       [9.99803662e-01],\n",
       "       [7.28714317e-02],\n",
       "       [1.81137904e-04],\n",
       "       [9.99707401e-01],\n",
       "       [2.35505591e-04],\n",
       "       [9.64009669e-03],\n",
       "       [5.72027639e-04],\n",
       "       [2.39832653e-03],\n",
       "       [4.97396989e-03],\n",
       "       [6.06647506e-03],\n",
       "       [9.56903957e-03],\n",
       "       [4.50155372e-03],\n",
       "       [9.99832928e-01],\n",
       "       [1.00178923e-03],\n",
       "       [1.02377811e-03],\n",
       "       [9.05129500e-03],\n",
       "       [3.13074235e-03],\n",
       "       [8.79229628e-05],\n",
       "       [3.26844491e-03],\n",
       "       [6.11058017e-03],\n",
       "       [1.33364054e-03],\n",
       "       [5.85655216e-04],\n",
       "       [9.54215575e-05],\n",
       "       [1.15242670e-03],\n",
       "       [9.99592185e-01],\n",
       "       [4.47006971e-02],\n",
       "       [2.04268974e-04],\n",
       "       [9.99432504e-01],\n",
       "       [2.02589259e-02],\n",
       "       [6.47095294e-05],\n",
       "       [4.56128549e-03],\n",
       "       [9.99224544e-01],\n",
       "       [9.98463273e-01],\n",
       "       [2.69012991e-04],\n",
       "       [6.33422984e-04],\n",
       "       [9.99761522e-01],\n",
       "       [9.99517620e-01],\n",
       "       [2.94997044e-05],\n",
       "       [2.72951875e-04],\n",
       "       [1.04094262e-03],\n",
       "       [8.21653381e-03],\n",
       "       [1.54955022e-03],\n",
       "       [9.32403127e-05],\n",
       "       [1.10632153e-02],\n",
       "       [6.53399155e-03],\n",
       "       [9.95558202e-01],\n",
       "       [2.09729245e-04],\n",
       "       [9.72082664e-04],\n",
       "       [4.35661605e-05],\n",
       "       [4.03760336e-02],\n",
       "       [8.67882161e-04],\n",
       "       [1.40786273e-04],\n",
       "       [1.06091247e-04],\n",
       "       [6.35259924e-03],\n",
       "       [4.96459776e-04],\n",
       "       [3.02444841e-03],\n",
       "       [4.57067508e-04],\n",
       "       [2.71603290e-04],\n",
       "       [9.99979734e-01],\n",
       "       [4.11594026e-02],\n",
       "       [1.64574158e-04],\n",
       "       [7.50851855e-02],\n",
       "       [1.71547849e-03],\n",
       "       [9.99505401e-01],\n",
       "       [9.32270705e-05],\n",
       "       [2.24543503e-04],\n",
       "       [1.27634150e-03],\n",
       "       [7.09378437e-05],\n",
       "       [2.65292503e-04],\n",
       "       [5.61980437e-03],\n",
       "       [2.13741604e-03],\n",
       "       [1.19532342e-04],\n",
       "       [3.32284952e-03],\n",
       "       [3.25146387e-03],\n",
       "       [2.77256430e-03],\n",
       "       [1.08973868e-02],\n",
       "       [1.08297943e-04],\n",
       "       [6.91942056e-04],\n",
       "       [2.51581430e-01],\n",
       "       [4.05712333e-03],\n",
       "       [1.88071950e-04],\n",
       "       [9.58309546e-02],\n",
       "       [4.74143511e-04],\n",
       "       [2.87898593e-02],\n",
       "       [2.29424884e-04],\n",
       "       [9.33187842e-01],\n",
       "       [1.01586556e-06],\n",
       "       [2.46471935e-03],\n",
       "       [9.98926818e-01],\n",
       "       [9.99934435e-01],\n",
       "       [3.37438541e-05],\n",
       "       [9.98303056e-01],\n",
       "       [6.68010689e-05],\n",
       "       [2.18852307e-03],\n",
       "       [1.20997231e-03],\n",
       "       [4.67864775e-05],\n",
       "       [3.56717064e-04],\n",
       "       [9.98968065e-01],\n",
       "       [9.67279315e-01],\n",
       "       [2.26947868e-05],\n",
       "       [3.18618282e-03],\n",
       "       [9.99678612e-01],\n",
       "       [9.82733764e-05],\n",
       "       [1.13730819e-03],\n",
       "       [9.99491990e-01],\n",
       "       [8.97749444e-04],\n",
       "       [1.08901318e-02],\n",
       "       [4.64307523e-04],\n",
       "       [5.81423426e-03],\n",
       "       [8.07153806e-03],\n",
       "       [5.53656078e-04],\n",
       "       [5.72690088e-03],\n",
       "       [1.55286910e-03],\n",
       "       [1.82268675e-03],\n",
       "       [1.18442317e-02],\n",
       "       [9.99207958e-04],\n",
       "       [9.99611139e-01],\n",
       "       [1.25936978e-02],\n",
       "       [9.99053061e-01],\n",
       "       [1.50429888e-03],\n",
       "       [2.33633652e-01],\n",
       "       [9.98662412e-01],\n",
       "       [9.09682785e-05],\n",
       "       [9.99651790e-01],\n",
       "       [1.26315921e-03],\n",
       "       [1.24660297e-03],\n",
       "       [1.23456807e-03],\n",
       "       [9.99034643e-01],\n",
       "       [9.99756515e-01],\n",
       "       [4.02150443e-04],\n",
       "       [4.67285099e-05],\n",
       "       [1.08837012e-04],\n",
       "       [5.79489337e-04],\n",
       "       [1.74221322e-02],\n",
       "       [1.15639037e-02],\n",
       "       [9.72566247e-01],\n",
       "       [2.09161313e-04],\n",
       "       [3.17487773e-03],\n",
       "       [4.24126483e-04],\n",
       "       [9.99850392e-01],\n",
       "       [5.11255767e-03],\n",
       "       [1.62271224e-02],\n",
       "       [6.13492727e-01],\n",
       "       [5.65188704e-03],\n",
       "       [1.84323762e-05],\n",
       "       [8.40915618e-06],\n",
       "       [9.42743034e-04],\n",
       "       [1.23788859e-03],\n",
       "       [1.58075115e-03],\n",
       "       [1.18666829e-03],\n",
       "       [9.98526871e-01],\n",
       "       [7.43047567e-04],\n",
       "       [1.28108377e-05],\n",
       "       [4.21920456e-02],\n",
       "       [4.30492545e-03],\n",
       "       [7.85809662e-03],\n",
       "       [1.34866685e-04],\n",
       "       [1.50351711e-02],\n",
       "       [1.83701719e-04],\n",
       "       [1.20434132e-04],\n",
       "       [1.31316367e-04],\n",
       "       [7.05712242e-04],\n",
       "       [1.26739571e-04],\n",
       "       [5.36768325e-03],\n",
       "       [8.27337426e-05],\n",
       "       [2.19940179e-04],\n",
       "       [9.98214066e-01],\n",
       "       [1.99960647e-04],\n",
       "       [2.54615839e-03],\n",
       "       [9.93726432e-01],\n",
       "       [4.37648443e-04],\n",
       "       [1.87437818e-03],\n",
       "       [1.94474659e-03],\n",
       "       [1.36349432e-03],\n",
       "       [9.99927223e-01],\n",
       "       [2.54685234e-04],\n",
       "       [3.77949909e-05],\n",
       "       [1.19468990e-04],\n",
       "       [5.59652472e-05],\n",
       "       [9.05920751e-04],\n",
       "       [1.12294266e-03],\n",
       "       [1.80438044e-03],\n",
       "       [1.54195077e-04],\n",
       "       [2.89389826e-02],\n",
       "       [1.49456342e-03],\n",
       "       [9.98819292e-01],\n",
       "       [2.60071550e-03],\n",
       "       [5.76960374e-05],\n",
       "       [3.92112415e-04],\n",
       "       [1.55816688e-05],\n",
       "       [6.95776835e-05],\n",
       "       [9.99285936e-01],\n",
       "       [1.79903596e-04],\n",
       "       [1.25467102e-03],\n",
       "       [4.95407730e-03],\n",
       "       [3.77741759e-03],\n",
       "       [1.96570810e-03],\n",
       "       [3.87335755e-03],\n",
       "       [2.68621108e-04],\n",
       "       [7.68831960e-05],\n",
       "       [3.95373516e-02],\n",
       "       [2.71987577e-04],\n",
       "       [8.64527319e-05],\n",
       "       [1.45255984e-03],\n",
       "       [1.99269576e-04],\n",
       "       [8.92191008e-03],\n",
       "       [4.55752030e-07],\n",
       "       [2.07614936e-02],\n",
       "       [1.22765535e-02],\n",
       "       [1.00490193e-04],\n",
       "       [3.23514454e-02],\n",
       "       [9.99871314e-01],\n",
       "       [2.78369002e-02],\n",
       "       [3.44818982e-04],\n",
       "       [4.55907662e-04],\n",
       "       [2.96616985e-04]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ¿Qué contiene pred_test? ¿Qué son?\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir las predicciones a clases (spam o no spam)\n",
    "# La salida será un valor entre 0 y 1 (probabilidad de spam)\n",
    "predicted_labels = (pred_test > 0.5).astype(int)  # Clasifica como spam (1) si la probabilidad > 0.5, sino no spam (0)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados conjunto de test:\n",
      "\n",
      "Accuracy: 0.98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       659\n",
      "           1       0.97      0.94      0.95       147\n",
      "\n",
      "    accuracy                           0.98       806\n",
      "   macro avg       0.98      0.97      0.97       806\n",
      "weighted avg       0.98      0.98      0.98       806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el \"classification report\" y \"accuracy\"\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print('Resultados conjunto de test:\\n')\n",
    "print(f'Accuracy: {accuracy:.2f}\\n')\n",
    "print(classification_report(y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal Compleja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning con un Modelo Preentrenado\n",
    "\n",
    "DistilBERT (una versión más ligera de BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el tokenizer de DistilBERT\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'vocab_layer_norm', 'activation_13', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_19']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16/26 [=================>............] - ETA: 4:40 - loss: 1.1237 - accuracy: 0.7778"
     ]
    }
   ],
   "source": [
    "# Tokenización de los textos\n",
    "X_train_enc = tokenizer(list(X_train), padding=True, truncation=True, max_length=100, return_tensors='tf')\n",
    "X_test_enc = tokenizer(list(X_test), padding=True, truncation=True, max_length=100, return_tensors='tf')\n",
    "\n",
    "# Cargar el modelo preentrenado DistilBERT para clasificación de texto\n",
    "model_bert = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "# Compilar el modelo\n",
    "model_bert.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento con transfer learning\n",
    "model_bert.fit(X_train_enc['input_ids'], y_train, epochs=3, batch_size=128, validation_data=(X_test_enc['input_ids'], y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trust_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
