{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelado\n",
    "\n",
    "En este notebook utilizaremos los conjuntos que hemos inspeccionado, adecuado y preprocesado para entrenar modelos que nos ayuden a analizar los mensajes de texto y detectar si se trata de **spam** o no.\n",
    "\n",
    "El siguiente script está dividido en los siguientes bloques:\n",
    "\n",
    "- **BLOQUE A**: carga de datos preprocesados.\n",
    "- **BLOQUE B**: entrenamiento y inferencia con distintos modelos de ML.\n",
    "- **BLOQUE C**: entrenamiento y inferencia con una red neuronal (librería Keras).\n",
    "- **BLOQUE D**: transfer learning con un modelo preentrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 16:17:37.410259: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-26 16:17:38.192827: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-26 16:17:38.192979: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-26 16:17:38.197821: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-26 16:17:38.570266: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-26 16:17:38.571971: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-26 16:17:42.755666: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from transformers import TFDistilBertForSequenceClassification, DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOQUE A: Carga de datos\n",
    "Antes de comenzar, cargaremos los datos que han sido adecuados en nuestra fase anterior de preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga textos vectorizados\n",
    "with open('../data/x_train_vec.pkl', 'rb') as f:\n",
    "    X_train_vec = pickle.load(f)\n",
    "\n",
    "with open('../data/x_test_vec.pkl', 'rb') as f:\n",
    "    X_test_vec = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga conjuntos de las etiquetas\n",
    "with open('../data/y_train.pkl', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open('../data/y_test.pkl', 'rb') as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOQUE B: Entrenamiento de distinto modelos de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión logistica\n",
    "\n",
    "La regresión logística es un modelo estadístico para estudiar las relaciones entre un conjunto de variables cualitativas Xi y una variable cualitativa Y. Utilizando la función sigmoide, asigna valores entre 0 y 1, facilitando la predicción de categorías, como positivo o negativos, spam o no spam, en aplicaciones prácticas.\n",
    "\n",
    "Más información acerca de este modelo [aquí](https://cienciadedatos.net/documentos/py17-regresion-logistica-python.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo\n",
    "log_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento o ajuste del modelo con los datos de entrenamiento\n",
    "log_model.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados conjunto de entrenamiento:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.99      0.97       590\n",
      "        spam       0.99      0.96      0.97       590\n",
      "\n",
      "    accuracy                           0.97      1180\n",
      "   macro avg       0.97      0.97      0.97      1180\n",
      "weighted avg       0.97      0.97      0.97      1180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos sobre los datos de entrenamiento\n",
    "y_pred_train = log_model.predict(X_train_vec)\n",
    "\n",
    "# Mostramos el \"classification report\"\n",
    "print('Resultados conjunto de entrenamiento:\\n')\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados conjunto de test:\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.98      0.98       659\n",
      "        spam       0.92      0.93      0.92       147\n",
      "\n",
      "    accuracy                           0.97       806\n",
      "   macro avg       0.95      0.95      0.95       806\n",
      "weighted avg       0.97      0.97      0.97       806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos sobre los datos de test\n",
    "y_pred_test = log_model.predict(X_test_vec)\n",
    "\n",
    "# Mostramos el \"classification report\" y \"accuracy\"\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print('Resultados conjunto de test:\\n')\n",
    "print(f'Accuracy: {accuracy:.2f}\\n')\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué es Boosting?\n",
    "\n",
    "Boosting es un meta-algoritmo de aprendizaje automático que reduce el sesgo y la varianza en un contexto de aprendizaje supervisado. Consiste en combinar los resultados de varios clasificadores débiles para obtener un clasificador robusto. Cuando se añaden estos clasificadores débiles, se hace de modo que éstos tengan diferente peso en función de la exactitud de sus predicciones. Tras añadir un clasificador débil, los datos cambian su estructura de pesos: los casos mal clasificados ganan peso y los que son clasificados correctamente pierden peso.\n",
    "\n",
    "**Gradient Boosting (GB)** o Potenciación del gradiente consiste en plantear el problema como una optimización numérica en el que el objetivo es minimizar una función de coste añadiendo clasificadores débiles mediante el descenso del gradiente. Involucra tres elementos:\n",
    "\n",
    "- La **función de coste** a optimizar: depende del tipo de problema a resolver.\n",
    "- Un **clasificador débil** para hacer las predicciones: por lo general se usan árboles de decisión.\n",
    "- Un **modelo que añade (ensambla) los clasificadores débiles para minimizar la función de coste**: se usa el descenso del gradiente para minimizar el coste al añadir árboles.\n",
    "\n",
    "Los hiperparámetros más importantes que intervienen en este algoritmo (aunque no todos) son:\n",
    "\n",
    "- **learning_rate**: determina el impacto de cada árbol en la salida final. Se parte de una estimación inicial que se va actualizando con la salida de cada árbol. Es el parámetro que controla la magnitud de las actualizaciones.\n",
    "- **n_estimators**: número de clasificadores débiles a utilizar.\n",
    "\n",
    "Como en este caso utilizaremos árboles de decisión como clasificadores débiles a ensamblar, también debemos tener en cuenta los hiperparámetros que afectan a esta clase de modelos. En este caso:\n",
    "\n",
    "- **max_depth**: profundidad máxima del árbol.\n",
    "\n",
    "Más información sobre el modelo que se utiliza en este ejemplo y de sus parámetros [aquí](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo introduciendo los valores de los parámetros:\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=150, learning_rate=0.2, max_depth=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=0.2, n_estimators=150, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.2, n_estimators=150, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.2, n_estimators=150, random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento o ajuste del modelo con los datos de entrenamiento\n",
    "gb_clf.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados conjunto de entrenamiento:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00       590\n",
      "        spam       1.00      1.00      1.00       590\n",
      "\n",
      "    accuracy                           1.00      1180\n",
      "   macro avg       1.00      1.00      1.00      1180\n",
      "weighted avg       1.00      1.00      1.00      1180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos sobre los datos de entrenamiento\n",
    "pred_train = gb_clf.predict(X_train_vec)\n",
    "\n",
    "# Mostramos el \"classification report\"\n",
    "print('Resultados conjunto de entrenamiento:\\n')\n",
    "print(classification_report(y_train, pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados conjunto de test:\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.95      0.97       659\n",
      "        spam       0.80      0.93      0.86       147\n",
      "\n",
      "    accuracy                           0.95       806\n",
      "   macro avg       0.89      0.94      0.91       806\n",
      "weighted avg       0.95      0.95      0.95       806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecimos sobre los datos de test\n",
    "pred_test = gb_clf.predict(X_test_vec)\n",
    "\n",
    "# Mostramos el \"classification report\" y \"accuracy\"\n",
    "accuracy = accuracy_score(y_test, pred_test)\n",
    "print('Resultados conjunto de test:\\n')\n",
    "print(f'Accuracy: {accuracy:.2f}\\n')\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOQUE C: entrenamiento y inferencia con una red neuronal (librería Keras)\n",
    "\n",
    "Las redes neuronales artificiales son una rama de la Inteligencia Artificial que se basa en la simulación de la estructura y funcionamiento del cerebro humano para procesar información.\n",
    "\n",
    "Consisten en una serie de nodos interconectados que reciben información, la procesan y producen una salida. Dichos nodos, conocidos como neuronas artificiales, pueden ser ajustados para optimizar la salida de la red, lo que permite que la red aprenda y se adapte a diferentes tipos de entradas.\n",
    "\n",
    "*Curiosidad: cuando una red neuronal tiene simplemente más de tres capas, nace el conocido como **Deep Learning** o aprendizaje profundo.*\n",
    "\n",
    "Más información sobre este tipo de modelos [aquí](https://openwebinars.net/blog/que-son-las-redes-neuronales-y-sus-aplicaciones/).\n",
    "\n",
    "En este caso, entrenaremos la red para que también obtenga una representación de los textos analizados de manera directa, sin necesidad de utilizar el modelo de vectorizado TF-IDF antes calculado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text  length\n",
       "0    ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "2    ham  U dun say so early hor... U c already then say...      49\n",
       "3    ham  Nah I don't think he goes to usf, he lives aro...      61\n",
       "4   spam  FreeMsg Hey there darling it's been 3 week's n...     148"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el dataset (ajusta la ruta según el archivo que tengas)\n",
    "df = pd.read_csv('../data/spam_filtered.csv')\n",
    "\n",
    "# Verifica el dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento del texto\n",
    "X = df['text']  # Supón que la columna 'text' contiene los mensajes\n",
    "y = df['target']  # 'label' debe ser spam/no spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las etiquetas 'spam'/'ham' a números\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ¿Que valores asume la variale target transformada? \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam', 'ham', ..., 'ham', 'ham', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ¿A qué corresponden los nuevos valores?\n",
    "df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenización y padding para convertir el texto en secuencias de enteros\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 370,\n",
       " 813,\n",
       " 5,\n",
       " 746,\n",
       " 69,\n",
       " 2401,\n",
       " 321,\n",
       " 88,\n",
       " 549,\n",
       " 300,\n",
       " 69,\n",
       " 2402,\n",
       " 2403,\n",
       " 2404,\n",
       " 321,\n",
       " 99,\n",
       " 814,\n",
       " 2405,\n",
       " 1893,\n",
       " 196,\n",
       " 116,\n",
       " 370,\n",
       " 815,\n",
       " 18,\n",
       " 2406,\n",
       " 116,\n",
       " 746,\n",
       " 2407,\n",
       " 65,\n",
       " 5,\n",
       " 2408,\n",
       " 57,\n",
       " 2409,\n",
       " 1179,\n",
       " 116,\n",
       " 746,\n",
       " 1894,\n",
       " 16,\n",
       " 57,\n",
       " 76,\n",
       " 18,\n",
       " 691,\n",
       " 116,\n",
       " 371,\n",
       " 116,\n",
       " 370,\n",
       " 1540,\n",
       " 56,\n",
       " 1180,\n",
       " 80,\n",
       " 1541,\n",
       " 99,\n",
       " 88,\n",
       " 494,\n",
       " 2410,\n",
       " 1895,\n",
       " 7,\n",
       " 495,\n",
       " 26,\n",
       " 692,\n",
       " 883,\n",
       " 116,\n",
       " 370,\n",
       " 1333,\n",
       " 1334,\n",
       " 9,\n",
       " 116,\n",
       " 693,\n",
       " 14,\n",
       " 11,\n",
       " 816,\n",
       " 80,\n",
       " 1896,\n",
       " 116,\n",
       " 371,\n",
       " 1897,\n",
       " 85,\n",
       " 816,\n",
       " 80,\n",
       " 2411,\n",
       " 2412,\n",
       " 2413,\n",
       " 2414,\n",
       " 1898,\n",
       " 1334,\n",
       " 2415,\n",
       " 1181,\n",
       " 14,\n",
       " 116,\n",
       " 694,\n",
       " 3,\n",
       " 1335,\n",
       " 47,\n",
       " 695,\n",
       " 116,\n",
       " 306,\n",
       " 817]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ¿Como son transformados los textos con Tokenizer?\n",
    "X_train_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding para asegurar que todas las secuencias tengan la misma longitud\n",
    "X_train_pad = pad_sequences(X_train_seq, padding='post', maxlen=100)\n",
    "X_test_pad = pad_sequences(X_test_seq, padding='post', maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estructura de la red neuronal:\n",
    "1. Capa de Embedding: \n",
    "    - input_dim=10000: Esto se refiere al tamaño del vocabulario (número total de palabras). \n",
    "\n",
    "    - output_dim=64: Este especifica la dimensión de los embeddings. En lugar de representar cada palabra con un valor binario o en un vector disperso (como ocurre con TF-IDF), las palabras se representarán por un vector denso de 64 dimensiones. \n",
    "\n",
    "    - input_length=100: se define la longitud máxima de las secuencias de entrada. Cada entrada de texto se convierte en una secuencia de índices de palabras (tokens), y si la longitud de una secuencia es menor que 100, se rellenará con ceros. Si es mayor, se truncará.\n",
    "2. Capa de Pooling: Esta capa realiza un *pooling global promedio* sobre las secuencias de embeddings. Dado que las entradas son secuencias de longitud 100, esta capa tomará el promedio de los vectores de embeddings de las 100 palabras (tokens) en la secuencia, lo que reduce la representación de la secuencia de una matriz de 100x64 a un solo vector de 64 dimensiones\n",
    "\n",
    "3. Capa densa (Fully connected): Esta capa toma la salida del pooling (un vector de 64 dimensiones) y lo pasa a través de una **capa densa con 64 neuronas** y la **función de activación ReLU**. Esto ayuda a la red a aprender características más complejas del texto procesado.\n",
    "\n",
    "4. Capa de salida: esta capa tiene una sola neurona con la **función de activación Sigmoid**, que es adecuada para clasificación binaria (en este caso, para clasificar como spam o no spam). La salida de esta capa será un valor entre 0 y 1, que puedes interpretar como la probabilidad de que un mensaje sea spam.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo simple de red neuronal para clasificación de texto\n",
    "nn_simple = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=10000, output_dim=64, input_length=100),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Para clasificación binaria (spam/no spam)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "101/101 [==============================] - 2s 12ms/step - loss: 0.5151 - accuracy: 0.8091 - val_loss: 0.4283 - val_accuracy: 0.8176\n",
      "Epoch 2/10\n",
      "101/101 [==============================] - 1s 13ms/step - loss: 0.3854 - accuracy: 0.8169 - val_loss: 0.3206 - val_accuracy: 0.8176\n",
      "Epoch 3/10\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 0.2252 - accuracy: 0.8973 - val_loss: 0.1493 - val_accuracy: 0.9615\n",
      "Epoch 4/10\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 0.0913 - accuracy: 0.9761 - val_loss: 0.0771 - val_accuracy: 0.9702\n",
      "Epoch 5/10\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 0.0493 - accuracy: 0.9854 - val_loss: 0.0638 - val_accuracy: 0.9826\n",
      "Epoch 6/10\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 0.0338 - accuracy: 0.9901 - val_loss: 0.0598 - val_accuracy: 0.9826\n",
      "Epoch 7/10\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 0.0251 - accuracy: 0.9929 - val_loss: 0.0557 - val_accuracy: 0.9814\n",
      "Epoch 8/10\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 0.0188 - accuracy: 0.9957 - val_loss: 0.0599 - val_accuracy: 0.9789\n",
      "Epoch 9/10\n",
      "101/101 [==============================] - 1s 12ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.0587 - val_accuracy: 0.9801\n",
      "Epoch 10/10\n",
      "101/101 [==============================] - 1s 11ms/step - loss: 0.0107 - accuracy: 0.9978 - val_loss: 0.0576 - val_accuracy: 0.9814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f67cc0735e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compilar el modelo\n",
    "nn_simple.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "nn_simple.fit(X_train_pad, y_train, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predecimos sobre los datos de test\n",
    "pred_test = nn_simple.predict(X_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.08566892e-04],\n",
       "       [9.99488473e-01],\n",
       "       [9.99765038e-01],\n",
       "       [8.28603879e-05],\n",
       "       [1.38014893e-03],\n",
       "       [2.03493983e-03],\n",
       "       [9.66416788e-04],\n",
       "       [3.72315873e-03],\n",
       "       [9.99837875e-01],\n",
       "       [1.19081314e-03],\n",
       "       [3.96732660e-03],\n",
       "       [7.28066802e-01],\n",
       "       [9.99416649e-01],\n",
       "       [7.30753964e-05],\n",
       "       [5.66092458e-05],\n",
       "       [8.50686152e-03],\n",
       "       [4.00147750e-04],\n",
       "       [4.45264959e-05],\n",
       "       [9.96309876e-01],\n",
       "       [3.33562421e-05],\n",
       "       [1.72596285e-03],\n",
       "       [4.91901301e-03],\n",
       "       [3.96300061e-03],\n",
       "       [9.99557078e-01],\n",
       "       [1.81678508e-03],\n",
       "       [2.83042667e-03],\n",
       "       [3.98756452e-02],\n",
       "       [9.99849498e-01],\n",
       "       [1.05822897e-02],\n",
       "       [4.52001055e-04],\n",
       "       [2.36934167e-04],\n",
       "       [5.02330018e-04],\n",
       "       [9.42510545e-01],\n",
       "       [9.51429248e-01],\n",
       "       [9.97791409e-01],\n",
       "       [9.99255657e-01],\n",
       "       [2.24135388e-02],\n",
       "       [1.64665151e-02],\n",
       "       [2.81183515e-04],\n",
       "       [1.26757503e-01],\n",
       "       [9.12381976e-04],\n",
       "       [9.98789191e-01],\n",
       "       [1.17074873e-03],\n",
       "       [9.99819040e-01],\n",
       "       [1.32636912e-02],\n",
       "       [9.98459816e-01],\n",
       "       [2.78835045e-03],\n",
       "       [4.64087847e-04],\n",
       "       [1.66977465e-03],\n",
       "       [1.11320266e-03],\n",
       "       [3.43312952e-03],\n",
       "       [1.51849622e-02],\n",
       "       [1.20869819e-02],\n",
       "       [5.41164866e-03],\n",
       "       [2.92519107e-02],\n",
       "       [9.99393642e-01],\n",
       "       [1.09682779e-03],\n",
       "       [9.99817789e-01],\n",
       "       [6.05683948e-04],\n",
       "       [3.42662307e-03],\n",
       "       [4.49874089e-04],\n",
       "       [6.04161210e-02],\n",
       "       [4.41548473e-04],\n",
       "       [5.34955226e-03],\n",
       "       [9.98954296e-01],\n",
       "       [8.89316738e-01],\n",
       "       [1.14724797e-03],\n",
       "       [7.53964472e-04],\n",
       "       [4.61179763e-03],\n",
       "       [1.16867748e-04],\n",
       "       [2.98069848e-04],\n",
       "       [2.35726517e-02],\n",
       "       [1.23204123e-02],\n",
       "       [9.99567807e-01],\n",
       "       [3.16065922e-03],\n",
       "       [3.02996626e-03],\n",
       "       [8.04578085e-05],\n",
       "       [1.37166819e-04],\n",
       "       [9.27383360e-03],\n",
       "       [1.09458622e-03],\n",
       "       [9.99850214e-01],\n",
       "       [9.99608874e-01],\n",
       "       [3.17039667e-04],\n",
       "       [3.69163317e-05],\n",
       "       [2.14895932e-04],\n",
       "       [3.74414580e-04],\n",
       "       [4.96133762e-05],\n",
       "       [1.93486951e-04],\n",
       "       [9.95486796e-01],\n",
       "       [9.94328260e-01],\n",
       "       [1.14724797e-03],\n",
       "       [1.69829617e-03],\n",
       "       [9.89028573e-01],\n",
       "       [5.61553461e-05],\n",
       "       [3.45792068e-05],\n",
       "       [1.26444851e-03],\n",
       "       [1.99570772e-04],\n",
       "       [9.36577283e-03],\n",
       "       [5.54500511e-05],\n",
       "       [4.74982662e-04],\n",
       "       [2.82465451e-04],\n",
       "       [2.00554859e-04],\n",
       "       [2.10756794e-01],\n",
       "       [2.27191439e-03],\n",
       "       [2.25022938e-02],\n",
       "       [1.45989726e-03],\n",
       "       [3.17939237e-04],\n",
       "       [2.81920866e-03],\n",
       "       [2.51278258e-03],\n",
       "       [9.99327898e-01],\n",
       "       [5.30551304e-04],\n",
       "       [9.99441683e-01],\n",
       "       [2.44850619e-03],\n",
       "       [5.62504074e-03],\n",
       "       [9.99491811e-01],\n",
       "       [1.94332999e-04],\n",
       "       [1.76874641e-03],\n",
       "       [9.99507666e-01],\n",
       "       [5.18216839e-05],\n",
       "       [4.19973442e-03],\n",
       "       [7.38697639e-03],\n",
       "       [9.58622550e-05],\n",
       "       [1.42179271e-02],\n",
       "       [2.08972953e-03],\n",
       "       [3.01465131e-02],\n",
       "       [2.71433755e-03],\n",
       "       [9.99397397e-01],\n",
       "       [9.96730328e-01],\n",
       "       [1.09061543e-02],\n",
       "       [1.02282007e-04],\n",
       "       [2.15292166e-04],\n",
       "       [8.49773824e-06],\n",
       "       [1.10319597e-04],\n",
       "       [5.22285427e-06],\n",
       "       [3.58370185e-01],\n",
       "       [8.81996879e-04],\n",
       "       [9.99502182e-01],\n",
       "       [1.24165547e-06],\n",
       "       [6.14770781e-03],\n",
       "       [2.90747033e-03],\n",
       "       [9.21835229e-02],\n",
       "       [1.12641882e-03],\n",
       "       [2.30774982e-03],\n",
       "       [3.83893512e-02],\n",
       "       [5.22613153e-03],\n",
       "       [9.99301791e-01],\n",
       "       [3.97392840e-04],\n",
       "       [1.50514636e-02],\n",
       "       [3.99217504e-04],\n",
       "       [9.78995347e-04],\n",
       "       [6.43425435e-03],\n",
       "       [6.12548436e-04],\n",
       "       [8.71516677e-05],\n",
       "       [4.78270650e-03],\n",
       "       [3.67112760e-03],\n",
       "       [7.28643499e-04],\n",
       "       [2.25833971e-02],\n",
       "       [8.04378578e-05],\n",
       "       [6.70819506e-02],\n",
       "       [9.56222534e-01],\n",
       "       [4.60787909e-03],\n",
       "       [7.22924480e-03],\n",
       "       [1.41908205e-03],\n",
       "       [2.65934767e-04],\n",
       "       [9.99571323e-01],\n",
       "       [4.93219262e-03],\n",
       "       [1.17721574e-04],\n",
       "       [2.52731983e-03],\n",
       "       [4.77027101e-03],\n",
       "       [1.34254024e-05],\n",
       "       [2.53826322e-04],\n",
       "       [7.08202183e-01],\n",
       "       [7.11648818e-03],\n",
       "       [1.59722231e-02],\n",
       "       [5.83498785e-03],\n",
       "       [8.76099584e-05],\n",
       "       [1.22621069e-02],\n",
       "       [1.82049916e-05],\n",
       "       [5.19767823e-03],\n",
       "       [8.83627450e-04],\n",
       "       [7.79660695e-05],\n",
       "       [3.05718306e-04],\n",
       "       [3.75061436e-03],\n",
       "       [2.63349531e-04],\n",
       "       [8.43929010e-05],\n",
       "       [2.01026630e-02],\n",
       "       [9.67496455e-01],\n",
       "       [4.23451798e-04],\n",
       "       [2.18151996e-04],\n",
       "       [3.36498255e-04],\n",
       "       [6.71346788e-05],\n",
       "       [2.84501933e-04],\n",
       "       [8.79437570e-03],\n",
       "       [1.24626386e-04],\n",
       "       [1.15758611e-03],\n",
       "       [2.02311548e-05],\n",
       "       [2.95988500e-01],\n",
       "       [6.24063949e-04],\n",
       "       [9.96068120e-01],\n",
       "       [1.02468848e-03],\n",
       "       [6.53099996e-05],\n",
       "       [9.62788472e-04],\n",
       "       [2.81993508e-01],\n",
       "       [6.96932024e-04],\n",
       "       [1.17492462e-04],\n",
       "       [9.96257305e-01],\n",
       "       [5.45314571e-04],\n",
       "       [2.91609875e-04],\n",
       "       [4.05343046e-04],\n",
       "       [4.86417674e-04],\n",
       "       [9.99670863e-01],\n",
       "       [3.14734504e-03],\n",
       "       [5.58365230e-03],\n",
       "       [1.45691074e-02],\n",
       "       [5.92564605e-03],\n",
       "       [1.17024139e-03],\n",
       "       [2.10445398e-03],\n",
       "       [6.67065009e-03],\n",
       "       [9.99903738e-01],\n",
       "       [6.08303308e-01],\n",
       "       [7.61024002e-03],\n",
       "       [1.01787189e-03],\n",
       "       [1.89996734e-02],\n",
       "       [8.13769177e-03],\n",
       "       [7.63094286e-03],\n",
       "       [6.28996466e-04],\n",
       "       [3.49119073e-04],\n",
       "       [2.96553178e-03],\n",
       "       [8.02600570e-03],\n",
       "       [8.19574390e-03],\n",
       "       [9.99579787e-01],\n",
       "       [1.12983298e-05],\n",
       "       [9.12381976e-04],\n",
       "       [3.59949120e-03],\n",
       "       [6.73051272e-06],\n",
       "       [5.80017157e-02],\n",
       "       [3.60909477e-03],\n",
       "       [1.52616063e-04],\n",
       "       [1.37355833e-04],\n",
       "       [4.20776516e-04],\n",
       "       [2.67950189e-03],\n",
       "       [1.83887823e-04],\n",
       "       [2.74564582e-03],\n",
       "       [7.77839720e-02],\n",
       "       [1.13758282e-03],\n",
       "       [1.40855322e-03],\n",
       "       [2.29517813e-03],\n",
       "       [6.85796887e-03],\n",
       "       [1.25952007e-04],\n",
       "       [1.28659711e-04],\n",
       "       [9.95364666e-01],\n",
       "       [7.10473978e-04],\n",
       "       [1.23429752e-04],\n",
       "       [4.71462756e-01],\n",
       "       [1.57848597e-04],\n",
       "       [5.01125958e-03],\n",
       "       [4.40695509e-03],\n",
       "       [1.20067624e-02],\n",
       "       [9.92010772e-01],\n",
       "       [2.32214271e-03],\n",
       "       [5.43710659e-04],\n",
       "       [9.98871565e-01],\n",
       "       [8.69018375e-04],\n",
       "       [8.44701752e-03],\n",
       "       [6.53613999e-04],\n",
       "       [9.38433077e-05],\n",
       "       [4.66184392e-05],\n",
       "       [9.09592723e-04],\n",
       "       [5.96387508e-06],\n",
       "       [1.59495289e-03],\n",
       "       [5.33101916e-01],\n",
       "       [1.41830518e-04],\n",
       "       [9.99882579e-01],\n",
       "       [9.98955071e-01],\n",
       "       [9.38354433e-03],\n",
       "       [1.43858986e-02],\n",
       "       [7.40994801e-05],\n",
       "       [8.94698221e-03],\n",
       "       [1.07605727e-02],\n",
       "       [1.63533143e-04],\n",
       "       [4.22077901e-05],\n",
       "       [2.93874145e-05],\n",
       "       [3.77730955e-03],\n",
       "       [1.47297993e-04],\n",
       "       [9.99941468e-01],\n",
       "       [5.21771610e-04],\n",
       "       [1.07817054e-04],\n",
       "       [3.66523687e-04],\n",
       "       [1.98386740e-02],\n",
       "       [1.44482736e-04],\n",
       "       [9.98141348e-01],\n",
       "       [2.85108341e-03],\n",
       "       [2.94425816e-04],\n",
       "       [2.12236614e-06],\n",
       "       [9.54197764e-01],\n",
       "       [2.08257479e-04],\n",
       "       [6.15383731e-03],\n",
       "       [1.34569040e-04],\n",
       "       [9.92587864e-01],\n",
       "       [3.91309935e-04],\n",
       "       [1.58307403e-02],\n",
       "       [1.27083249e-03],\n",
       "       [6.35461538e-06],\n",
       "       [8.96082103e-01],\n",
       "       [3.16772872e-04],\n",
       "       [1.10750936e-03],\n",
       "       [1.69489477e-02],\n",
       "       [2.02966636e-04],\n",
       "       [9.98308420e-01],\n",
       "       [6.42193540e-04],\n",
       "       [1.76802187e-05],\n",
       "       [7.35491776e-05],\n",
       "       [9.98872757e-01],\n",
       "       [4.30993350e-06],\n",
       "       [2.16694130e-03],\n",
       "       [9.98674273e-01],\n",
       "       [6.22186053e-04],\n",
       "       [1.34565285e-03],\n",
       "       [9.91649210e-01],\n",
       "       [9.99196529e-01],\n",
       "       [9.99322355e-01],\n",
       "       [2.60221902e-02],\n",
       "       [1.75100181e-03],\n",
       "       [1.02343372e-04],\n",
       "       [1.38374628e-04],\n",
       "       [3.24134271e-06],\n",
       "       [8.92714318e-03],\n",
       "       [9.78619754e-01],\n",
       "       [3.01154996e-05],\n",
       "       [1.47769824e-04],\n",
       "       [4.20240569e-04],\n",
       "       [9.92555797e-01],\n",
       "       [2.59827473e-03],\n",
       "       [9.30860490e-02],\n",
       "       [9.99592543e-01],\n",
       "       [9.97973323e-01],\n",
       "       [2.81821872e-06],\n",
       "       [6.66145235e-03],\n",
       "       [1.51632878e-04],\n",
       "       [8.20795132e-04],\n",
       "       [7.98476711e-02],\n",
       "       [3.39071453e-03],\n",
       "       [9.99444008e-01],\n",
       "       [9.98985827e-01],\n",
       "       [1.39359399e-05],\n",
       "       [1.10035145e-03],\n",
       "       [8.75220355e-03],\n",
       "       [9.99099493e-01],\n",
       "       [1.81516371e-04],\n",
       "       [2.96533864e-04],\n",
       "       [2.63707425e-05],\n",
       "       [5.64255053e-03],\n",
       "       [7.94606385e-05],\n",
       "       [1.73486900e-04],\n",
       "       [5.29369805e-03],\n",
       "       [3.81457335e-06],\n",
       "       [1.38490159e-05],\n",
       "       [7.67354846e-01],\n",
       "       [1.86428626e-03],\n",
       "       [2.27010023e-04],\n",
       "       [3.14496137e-04],\n",
       "       [2.26173928e-04],\n",
       "       [2.16271874e-04],\n",
       "       [7.23227931e-05],\n",
       "       [2.35492116e-04],\n",
       "       [3.77984048e-04],\n",
       "       [3.09999916e-04],\n",
       "       [1.97075750e-03],\n",
       "       [3.29968799e-03],\n",
       "       [3.69071524e-04],\n",
       "       [8.59022327e-03],\n",
       "       [6.50093332e-03],\n",
       "       [4.13360680e-03],\n",
       "       [1.48939127e-02],\n",
       "       [9.04315733e-04],\n",
       "       [3.20407143e-03],\n",
       "       [2.47843651e-04],\n",
       "       [4.52230545e-03],\n",
       "       [9.96605396e-01],\n",
       "       [9.09054652e-04],\n",
       "       [1.22611299e-02],\n",
       "       [1.06341322e-04],\n",
       "       [3.23559274e-03],\n",
       "       [8.82169043e-05],\n",
       "       [1.84256030e-04],\n",
       "       [9.97572005e-01],\n",
       "       [9.98209298e-01],\n",
       "       [4.21602279e-03],\n",
       "       [1.37598149e-03],\n",
       "       [8.95535350e-02],\n",
       "       [4.67909325e-04],\n",
       "       [1.22648620e-04],\n",
       "       [9.99401093e-01],\n",
       "       [2.25266698e-03],\n",
       "       [1.00753428e-02],\n",
       "       [5.48161508e-04],\n",
       "       [8.89316738e-01],\n",
       "       [9.99875724e-01],\n",
       "       [9.99324977e-01],\n",
       "       [2.17819214e-03],\n",
       "       [5.17235463e-03],\n",
       "       [8.69256139e-01],\n",
       "       [1.72563494e-04],\n",
       "       [1.29299669e-03],\n",
       "       [9.99764979e-01],\n",
       "       [4.23640566e-04],\n",
       "       [3.64572879e-05],\n",
       "       [2.74390855e-04],\n",
       "       [3.04192514e-03],\n",
       "       [2.35277457e-05],\n",
       "       [9.98950124e-01],\n",
       "       [9.99847949e-01],\n",
       "       [8.52145196e-04],\n",
       "       [1.22207333e-04],\n",
       "       [8.89702141e-01],\n",
       "       [6.54221440e-05],\n",
       "       [1.01057522e-03],\n",
       "       [6.95374911e-04],\n",
       "       [1.64192039e-04],\n",
       "       [3.31512420e-04],\n",
       "       [1.52363922e-04],\n",
       "       [1.63731482e-02],\n",
       "       [9.97830510e-01],\n",
       "       [7.91436934e-04],\n",
       "       [5.07095223e-03],\n",
       "       [3.04576522e-03],\n",
       "       [1.38400763e-04],\n",
       "       [9.97512341e-01],\n",
       "       [3.92998372e-05],\n",
       "       [1.91193318e-03],\n",
       "       [3.66053835e-04],\n",
       "       [1.22300014e-04],\n",
       "       [7.54432345e-04],\n",
       "       [1.91040020e-02],\n",
       "       [1.28663760e-02],\n",
       "       [1.67893173e-04],\n",
       "       [2.22438845e-04],\n",
       "       [4.90677594e-05],\n",
       "       [1.31379776e-02],\n",
       "       [5.27082849e-03],\n",
       "       [3.09942872e-04],\n",
       "       [1.20645296e-03],\n",
       "       [3.03264968e-02],\n",
       "       [1.38176852e-04],\n",
       "       [7.92233332e-04],\n",
       "       [9.99280214e-01],\n",
       "       [1.32841140e-03],\n",
       "       [4.91729634e-06],\n",
       "       [1.14724797e-03],\n",
       "       [1.13742310e-03],\n",
       "       [5.16195687e-05],\n",
       "       [1.66770313e-02],\n",
       "       [1.44065348e-02],\n",
       "       [8.47683637e-04],\n",
       "       [7.40758469e-03],\n",
       "       [1.18817145e-03],\n",
       "       [8.14332161e-03],\n",
       "       [9.99029458e-01],\n",
       "       [9.99386013e-01],\n",
       "       [1.95382303e-03],\n",
       "       [8.60001717e-04],\n",
       "       [1.62474535e-04],\n",
       "       [3.73910926e-03],\n",
       "       [1.23050078e-04],\n",
       "       [1.67583476e-05],\n",
       "       [8.06490832e-04],\n",
       "       [6.59423313e-05],\n",
       "       [9.89332199e-01],\n",
       "       [1.81263164e-01],\n",
       "       [4.34181541e-02],\n",
       "       [9.99325871e-01],\n",
       "       [9.99419808e-01],\n",
       "       [1.72635727e-02],\n",
       "       [1.91907492e-03],\n",
       "       [2.07390282e-02],\n",
       "       [4.99681220e-04],\n",
       "       [1.27272820e-03],\n",
       "       [9.98338938e-01],\n",
       "       [4.38223267e-03],\n",
       "       [2.58497448e-06],\n",
       "       [2.79608648e-04],\n",
       "       [3.12876818e-03],\n",
       "       [7.54422974e-04],\n",
       "       [8.24985188e-03],\n",
       "       [5.65749314e-03],\n",
       "       [9.98872757e-01],\n",
       "       [2.58709467e-03],\n",
       "       [3.05936672e-04],\n",
       "       [9.98425901e-01],\n",
       "       [2.48757913e-03],\n",
       "       [1.34493026e-03],\n",
       "       [6.04060537e-04],\n",
       "       [5.93525838e-05],\n",
       "       [5.39034954e-05],\n",
       "       [9.99890268e-01],\n",
       "       [3.17741255e-03],\n",
       "       [1.28747046e-03],\n",
       "       [3.43244076e-02],\n",
       "       [6.17113619e-05],\n",
       "       [4.11030604e-03],\n",
       "       [1.44042162e-04],\n",
       "       [8.65176335e-05],\n",
       "       [9.11732614e-01],\n",
       "       [4.69069444e-02],\n",
       "       [1.81499845e-03],\n",
       "       [1.38014893e-03],\n",
       "       [2.54792569e-04],\n",
       "       [2.74674036e-04],\n",
       "       [7.02069883e-05],\n",
       "       [2.89899530e-04],\n",
       "       [9.51759357e-05],\n",
       "       [7.36539997e-03],\n",
       "       [2.12086481e-04],\n",
       "       [9.99831438e-01],\n",
       "       [3.88435135e-03],\n",
       "       [9.99553978e-01],\n",
       "       [8.81612883e-04],\n",
       "       [5.55471983e-04],\n",
       "       [2.98477383e-03],\n",
       "       [3.60368897e-04],\n",
       "       [2.30774982e-03],\n",
       "       [9.06727836e-03],\n",
       "       [8.84130180e-01],\n",
       "       [2.17870111e-04],\n",
       "       [3.46454279e-03],\n",
       "       [1.32569661e-02],\n",
       "       [1.07593269e-05],\n",
       "       [9.99860942e-01],\n",
       "       [4.73094806e-02],\n",
       "       [1.43585625e-04],\n",
       "       [5.62240705e-02],\n",
       "       [4.02984163e-03],\n",
       "       [7.89316182e-05],\n",
       "       [9.99723375e-01],\n",
       "       [1.38669079e-02],\n",
       "       [1.18664820e-02],\n",
       "       [1.77930749e-03],\n",
       "       [8.86655629e-01],\n",
       "       [9.57341969e-01],\n",
       "       [1.22621069e-02],\n",
       "       [9.99512792e-01],\n",
       "       [1.68072234e-03],\n",
       "       [5.12661609e-05],\n",
       "       [9.98652577e-01],\n",
       "       [2.05080811e-04],\n",
       "       [2.90573062e-03],\n",
       "       [6.44694897e-04],\n",
       "       [2.65662256e-03],\n",
       "       [9.97518957e-01],\n",
       "       [3.30852792e-02],\n",
       "       [2.45731673e-04],\n",
       "       [1.66116608e-03],\n",
       "       [4.24578429e-05],\n",
       "       [2.55421561e-04],\n",
       "       [5.33624040e-03],\n",
       "       [1.64135825e-02],\n",
       "       [4.98063047e-04],\n",
       "       [2.03717951e-04],\n",
       "       [1.49043146e-04],\n",
       "       [1.89540500e-03],\n",
       "       [8.70938718e-01],\n",
       "       [5.01952445e-06],\n",
       "       [3.00550164e-04],\n",
       "       [5.56745217e-04],\n",
       "       [1.89754681e-03],\n",
       "       [4.05806059e-05],\n",
       "       [2.22293194e-03],\n",
       "       [1.51632878e-04],\n",
       "       [1.44349586e-04],\n",
       "       [5.22329901e-05],\n",
       "       [1.20789197e-03],\n",
       "       [1.08207212e-04],\n",
       "       [6.15142999e-05],\n",
       "       [9.11732614e-01],\n",
       "       [2.63839029e-02],\n",
       "       [2.92209238e-01],\n",
       "       [4.58943650e-05],\n",
       "       [2.98458966e-03],\n",
       "       [7.63227884e-03],\n",
       "       [8.57409905e-04],\n",
       "       [8.48986019e-05],\n",
       "       [1.83824711e-02],\n",
       "       [6.53086317e-05],\n",
       "       [1.50950644e-02],\n",
       "       [7.36408256e-05],\n",
       "       [1.14720417e-04],\n",
       "       [3.47874453e-03],\n",
       "       [2.72005476e-04],\n",
       "       [2.23340321e-04],\n",
       "       [8.41482019e-04],\n",
       "       [9.99626696e-01],\n",
       "       [5.42785935e-02],\n",
       "       [1.28701664e-04],\n",
       "       [9.99419808e-01],\n",
       "       [1.70631640e-04],\n",
       "       [6.82405801e-03],\n",
       "       [3.93883412e-04],\n",
       "       [1.69664202e-03],\n",
       "       [3.26497969e-03],\n",
       "       [4.41014906e-03],\n",
       "       [7.19709927e-03],\n",
       "       [2.82741920e-03],\n",
       "       [9.99637783e-01],\n",
       "       [7.98145251e-04],\n",
       "       [7.29273597e-04],\n",
       "       [5.67989284e-03],\n",
       "       [2.15177424e-03],\n",
       "       [6.29627102e-05],\n",
       "       [2.90331664e-03],\n",
       "       [4.33834316e-03],\n",
       "       [9.82536818e-04],\n",
       "       [4.76694200e-04],\n",
       "       [6.99513039e-05],\n",
       "       [7.32094748e-04],\n",
       "       [9.99269545e-01],\n",
       "       [2.55638044e-02],\n",
       "       [1.32745408e-04],\n",
       "       [9.98822927e-01],\n",
       "       [1.43272905e-02],\n",
       "       [4.77765934e-05],\n",
       "       [3.28505714e-03],\n",
       "       [9.98715937e-01],\n",
       "       [9.97804046e-01],\n",
       "       [1.64439421e-04],\n",
       "       [4.85681463e-04],\n",
       "       [9.99587238e-01],\n",
       "       [9.99107122e-01],\n",
       "       [1.83730244e-05],\n",
       "       [2.03047937e-04],\n",
       "       [8.65817710e-04],\n",
       "       [6.39829040e-03],\n",
       "       [9.85012972e-04],\n",
       "       [5.38643362e-05],\n",
       "       [6.60520699e-03],\n",
       "       [4.95076180e-03],\n",
       "       [9.92010772e-01],\n",
       "       [1.43027006e-04],\n",
       "       [5.42155525e-04],\n",
       "       [3.21680600e-05],\n",
       "       [2.35388391e-02],\n",
       "       [6.05312234e-04],\n",
       "       [1.04932602e-04],\n",
       "       [8.00092312e-05],\n",
       "       [3.53385555e-03],\n",
       "       [3.56303412e-04],\n",
       "       [2.24249251e-03],\n",
       "       [2.88674142e-04],\n",
       "       [1.75561348e-04],\n",
       "       [9.99956608e-01],\n",
       "       [3.00992522e-02],\n",
       "       [1.06922431e-04],\n",
       "       [5.58958948e-02],\n",
       "       [1.37741235e-03],\n",
       "       [9.99209702e-01],\n",
       "       [5.89537158e-05],\n",
       "       [1.72987071e-04],\n",
       "       [8.47198709e-04],\n",
       "       [5.28518431e-05],\n",
       "       [1.92807187e-04],\n",
       "       [3.44516407e-03],\n",
       "       [1.65010185e-03],\n",
       "       [7.25597347e-05],\n",
       "       [2.13874853e-03],\n",
       "       [2.32836395e-03],\n",
       "       [2.20511924e-03],\n",
       "       [5.98185556e-03],\n",
       "       [8.38061897e-05],\n",
       "       [4.63113189e-04],\n",
       "       [1.54548988e-01],\n",
       "       [2.71140365e-03],\n",
       "       [1.56616501e-04],\n",
       "       [6.28893822e-02],\n",
       "       [3.59463767e-04],\n",
       "       [1.46639990e-02],\n",
       "       [1.67872873e-04],\n",
       "       [8.69256139e-01],\n",
       "       [6.69466203e-07],\n",
       "       [1.58720696e-03],\n",
       "       [9.98000264e-01],\n",
       "       [9.99855518e-01],\n",
       "       [1.95783377e-05],\n",
       "       [9.97121871e-01],\n",
       "       [4.68834842e-05],\n",
       "       [1.53617549e-03],\n",
       "       [8.79077532e-04],\n",
       "       [3.75186210e-05],\n",
       "       [2.44422670e-04],\n",
       "       [9.98268545e-01],\n",
       "       [9.48055148e-01],\n",
       "       [1.73338922e-05],\n",
       "       [2.20417092e-03],\n",
       "       [9.99379635e-01],\n",
       "       [7.26047365e-05],\n",
       "       [7.28812651e-04],\n",
       "       [9.99181688e-01],\n",
       "       [7.30658940e-04],\n",
       "       [7.39324465e-03],\n",
       "       [3.59632715e-04],\n",
       "       [3.73110338e-03],\n",
       "       [6.14237878e-03],\n",
       "       [4.58335388e-04],\n",
       "       [4.05302877e-03],\n",
       "       [1.05961983e-03],\n",
       "       [1.06986414e-03],\n",
       "       [6.65648142e-03],\n",
       "       [6.76650438e-04],\n",
       "       [9.99315619e-01],\n",
       "       [7.85135664e-03],\n",
       "       [9.98606026e-01],\n",
       "       [1.03398634e-03],\n",
       "       [1.62273914e-01],\n",
       "       [9.97518957e-01],\n",
       "       [5.96957761e-05],\n",
       "       [9.99405622e-01],\n",
       "       [8.23385315e-04],\n",
       "       [1.02758605e-03],\n",
       "       [1.06164627e-03],\n",
       "       [9.98345912e-01],\n",
       "       [9.99515951e-01],\n",
       "       [3.31846648e-04],\n",
       "       [3.01154996e-05],\n",
       "       [7.08761727e-05],\n",
       "       [4.20222117e-04],\n",
       "       [1.15920231e-02],\n",
       "       [8.27482995e-03],\n",
       "       [9.51590598e-01],\n",
       "       [1.42049917e-04],\n",
       "       [2.17110338e-03],\n",
       "       [3.22993408e-04],\n",
       "       [9.99642432e-01],\n",
       "       [3.78085184e-03],\n",
       "       [1.21120997e-02],\n",
       "       [4.69355047e-01],\n",
       "       [3.60234478e-03],\n",
       "       [1.07023561e-05],\n",
       "       [6.10963662e-06],\n",
       "       [5.35832660e-04],\n",
       "       [8.50078766e-04],\n",
       "       [1.32699194e-03],\n",
       "       [1.03640766e-03],\n",
       "       [9.97506738e-01],\n",
       "       [5.52673242e-04],\n",
       "       [9.21985611e-06],\n",
       "       [3.18783037e-02],\n",
       "       [3.14893248e-03],\n",
       "       [6.07614266e-03],\n",
       "       [8.27645199e-05],\n",
       "       [8.27928726e-03],\n",
       "       [1.41830518e-04],\n",
       "       [7.76452507e-05],\n",
       "       [1.03524457e-04],\n",
       "       [5.16179542e-04],\n",
       "       [8.55906837e-05],\n",
       "       [2.77363090e-03],\n",
       "       [6.35093456e-05],\n",
       "       [1.71702632e-04],\n",
       "       [9.97113287e-01],\n",
       "       [1.42817677e-04],\n",
       "       [1.66295189e-03],\n",
       "       [9.89439368e-01],\n",
       "       [3.71974660e-04],\n",
       "       [1.20371697e-03],\n",
       "       [1.15908962e-03],\n",
       "       [1.03493209e-03],\n",
       "       [9.99852538e-01],\n",
       "       [1.82836186e-04],\n",
       "       [2.51135425e-05],\n",
       "       [8.81968881e-05],\n",
       "       [2.89657510e-05],\n",
       "       [5.12961007e-04],\n",
       "       [7.20220385e-04],\n",
       "       [1.26828463e-03],\n",
       "       [1.23057704e-04],\n",
       "       [1.95802692e-02],\n",
       "       [1.07795745e-03],\n",
       "       [9.98004556e-01],\n",
       "       [1.74711773e-03],\n",
       "       [3.89763554e-05],\n",
       "       [3.06059810e-04],\n",
       "       [1.05484887e-05],\n",
       "       [4.80590388e-05],\n",
       "       [9.98748183e-01],\n",
       "       [1.19093638e-04],\n",
       "       [7.68335478e-04],\n",
       "       [2.99048354e-03],\n",
       "       [2.38176249e-03],\n",
       "       [1.79075066e-03],\n",
       "       [2.75420467e-03],\n",
       "       [2.03717951e-04],\n",
       "       [5.88754556e-05],\n",
       "       [1.75235402e-02],\n",
       "       [1.89158571e-04],\n",
       "       [6.52755043e-05],\n",
       "       [1.05562375e-03],\n",
       "       [1.39417753e-04],\n",
       "       [6.39972929e-03],\n",
       "       [2.12483982e-07],\n",
       "       [1.27286157e-02],\n",
       "       [4.83774114e-03],\n",
       "       [7.20904645e-05],\n",
       "       [2.15140991e-02],\n",
       "       [9.99743998e-01],\n",
       "       [2.22351532e-02],\n",
       "       [2.87549308e-04],\n",
       "       [3.52124742e-04],\n",
       "       [2.21600552e-04]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ¿Qué contiene pred_test? ¿Qué son?\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir las predicciones a clases (spam o no spam)\n",
    "# La salida será un valor entre 0 y 1 (probabilidad de spam)\n",
    "predicted_labels = (pred_test > 0.5).astype(int)  # Clasifica como spam (1) si la probabilidad > 0.5, sino no spam (0)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados conjunto de test:\n",
      "\n",
      "Accuracy: 0.98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       659\n",
      "           1       0.97      0.93      0.95       147\n",
      "\n",
      "    accuracy                           0.98       806\n",
      "   macro avg       0.98      0.96      0.97       806\n",
      "weighted avg       0.98      0.98      0.98       806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el \"classification report\" y \"accuracy\"\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print('Resultados conjunto de test:\\n')\n",
    "print(f'Accuracy: {accuracy:.2f}\\n')\n",
    "print(classification_report(y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning con un modelo preentrenado\n",
    "\n",
    "**BERT** (Bidirectional Encoder Representations from Transformers) es una técnica basada en redes neuronales para el pre-entrenamiento del procesamiento del lenguaje natural (NLP) desarrollada por Google. Se trata de un codificador que obtiene representaciones bidireccionales, lo que significa que puede entender el significado de una palabra en relación con las palabras que la rodean. Esto permite al modelo aprender a **interpretar el lenguaje en general y ser utilizado como modelo base**, de manera que, en caso de querer especializarlo en una tarea en particular (detección de spams, por ejemplo), solo es necesario añadir unas capas adicionales al mismo.\n",
    "\n",
    "El modelo original de BERT se entrenó utilizando dos grandes conjuntos de datos en lengua inglesa: BookCorpus y Wikipedia en inglés. \n",
    "\n",
    "*Curiosidad: actualmente, Google utiliza BERT en su motor de búsqueda para perfeccionar la comprensión de las búsquedas de los usuarios.*\n",
    "\n",
    "Por su parte, **DistilBERT** (Distilled version of BERT) es una versión más ligera, rápida y menos costosa del modelo BERT, como su propio nombre indica.\n",
    "\n",
    "Más información acerca de BERT [aquí](https://huggingface.co/blog/bert-101), y de DistilBERT [aquí](https://huggingface.co/docs/transformers/model_doc/distilbert) y [aquí](https://medium.com/huggingface/distilbert-8cf3380435b5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cristian.robledo/anaconda3/envs/crypto_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cargar el tokenizer de DistilBERT\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 93s 93s/step - loss: 0.9321 - accuracy: 0.7400 - val_loss: 0.7608 - val_accuracy: 0.8176\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 80s 80s/step - loss: 1.4566 - accuracy: 0.8200 - val_loss: 1.0840 - val_accuracy: 0.8176\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 91s 91s/step - loss: 0.9741 - accuracy: 0.8200 - val_loss: 0.4520 - val_accuracy: 0.8176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f6799da4190>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenización de los textos\n",
    "X_train_enc = tokenizer(list(X_train[:100]), padding=True, truncation=True, max_length=100, return_tensors='tf') # Usamos 100 observaciones para poder ejecutarlo en local\n",
    "X_test_enc = tokenizer(list(X_test), padding=True, truncation=True, max_length=100, return_tensors='tf')\n",
    "\n",
    "# Cargar el modelo preentrenado DistilBERT para clasificación de texto\n",
    "model_bert = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "# Compilar el modelo\n",
    "model_bert.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento con transfer learning\n",
    "model_bert.fit(X_train_enc['input_ids'], y_train[:100], epochs=3, batch_size=128, validation_data=(X_test_enc['input_ids'], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 64s 2s/step - loss: 0.4520 - accuracy: 0.8176\n",
      "Accuracy DistilBERT model: 0.8176178932189941\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos sobre el conjunto de test y vemos métrica\n",
    "loss, accuracy = model_bert.evaluate(X_test_enc['input_ids'], y_test)\n",
    "print(f\"Accuracy DistilBERT model: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crypto_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
